---
title: Vertex AI + SHAP integration
description: Right to Explanation with explainable AI for high-risk clinical inferences
---

## Overview

iLuminara-Core integrates Google Cloud Vertex AI with SHAP (SHapley Additive exPlanations) to provide the **Right to Explanation** for every high-risk clinical inference, ensuring compliance with EU AI Act ¬ß6 and GDPR Art. 22.

<Card
  title="Compliance"
  icon="scale-balanced"
>
  Every high-risk inference automatically triggers SHAP analysis to comply with EU AI Act ¬ß6 (High-Risk AI) and GDPR Art. 22 (Right to Explanation).
</Card>

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         VERTEX AI                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  AutoML Time-Series          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - 72-hour forecasting       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Hierarchical models       ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚îÇ Prediction
              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         SHAP EXPLAINER              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Feature Importance          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - SHAP values               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Force plots               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Waterfall charts          ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚îÇ Explanation
              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         SOVEREIGN GUARDRAIL         ‚îÇ
‚îÇ  - Validates explanation quality    ‚îÇ
‚îÇ  - Enforces confidence thresholds   ‚îÇ
‚îÇ  - Logs to tamper-proof audit       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## High-risk inference detection

The SovereignGuardrail automatically detects high-risk inferences:

```python
from governance_kernel.vector_ledger import SovereignGuardrail

guardrail = SovereignGuardrail()

# High-risk threshold: confidence > 0.7
if prediction_confidence > 0.7:
    # Requires SHAP explanation
    guardrail.validate_action(
        action_type='High_Risk_Inference',
        payload={
            'inference': 'cholera_outbreak',
            'confidence_score': 0.92,
            'explanation': shap_values,
            'evidence_chain': ['fever', 'diarrhea', 'vomiting'],
            'consent_token': 'VALID_TOKEN',
            'consent_scope': 'diagnosis'
        },
        jurisdiction='EU_AI_ACT'
    )
```

## Vertex AI setup

### 1. Enable Vertex AI API

```bash
gcloud services enable aiplatform.googleapis.com
```

### 2. Create training dataset

```python
from google.cloud import aiplatform
from google.cloud import bigquery

# Initialize Vertex AI
aiplatform.init(
    project='your-project-id',
    location='us-central1'
)

# Create dataset from BigQuery
dataset = aiplatform.TimeSeriesDataset.create(
    display_name='cholera-outbreak-forecast',
    bq_source='bq://your-project.iluminara.outbreak_data',
    time_column='timestamp',
    time_series_identifier_column='location',
    target_column='case_count'
)
```

### 3. Train AutoML model

```python
# Create training job
job = aiplatform.AutoMLForecastingTrainingJob(
    display_name='cholera-forecast-model',
    optimization_objective='minimize-rmse',
    column_specs={
        'timestamp': 'timestamp',
        'location': 'categorical',
        'case_count': 'numeric',
        'temperature': 'numeric',
        'rainfall': 'numeric',
        'population_density': 'numeric'
    }
)

# Train model
model = job.run(
    dataset=dataset,
    target_column='case_count',
    time_column='timestamp',
    time_series_identifier_column='location',
    forecast_horizon=72,  # 72 hours
    data_granularity_unit='hour',
    data_granularity_count=1,
    training_fraction_split=0.8,
    validation_fraction_split=0.1,
    test_fraction_split=0.1
)
```

### 4. Deploy model

```python
# Deploy to endpoint
endpoint = model.deploy(
    machine_type='n1-standard-4',
    min_replica_count=1,
    max_replica_count=10,
    accelerator_type='NVIDIA_TESLA_T4',
    accelerator_count=1
)
```

## SHAP integration

### 1. Install SHAP

```bash
pip install shap
```

### 2. Create SHAP explainer

```python
import shap
import numpy as np
from google.cloud import aiplatform

# Load deployed model
endpoint = aiplatform.Endpoint('projects/123/locations/us-central1/endpoints/456')

# Create prediction function
def predict_fn(X):
    instances = [{'features': x.tolist()} for x in X]
    predictions = endpoint.predict(instances=instances)
    return np.array([p['value'] for p in predictions.predictions])

# Create SHAP explainer
explainer = shap.KernelExplainer(predict_fn, background_data)
```

### 3. Generate SHAP values

```python
# Get SHAP values for prediction
shap_values = explainer.shap_values(input_features)

# Feature importance
feature_importance = {
    'temperature': shap_values[0],
    'rainfall': shap_values[1],
    'population_density': shap_values[2],
    'previous_cases': shap_values[3]
}

print(f"Feature Importance: {feature_importance}")
```

### 4. Visualize explanations

```python
import matplotlib.pyplot as plt

# Force plot (single prediction)
shap.force_plot(
    explainer.expected_value,
    shap_values,
    input_features,
    matplotlib=True
)

# Waterfall chart
shap.waterfall_plot(
    shap.Explanation(
        values=shap_values,
        base_values=explainer.expected_value,
        data=input_features,
        feature_names=feature_names
    )
)

# Summary plot (multiple predictions)
shap.summary_plot(shap_values, input_features, feature_names=feature_names)
```

## Complete integration example

```python
from google.cloud import aiplatform
from governance_kernel.vector_ledger import SovereignGuardrail, SovereigntyViolationError
import shap
import numpy as np

class ExplainableVertexAI:
    """Vertex AI with mandatory SHAP explanations for high-risk inferences"""
    
    def __init__(self, endpoint_id: str, project: str, location: str):
        self.endpoint = aiplatform.Endpoint(
            f'projects/{project}/locations/{location}/endpoints/{endpoint_id}'
        )
        self.guardrail = SovereignGuardrail()
        self.high_risk_threshold = 0.7
        
        # Initialize SHAP explainer
        self.explainer = None  # Lazy initialization
    
    def predict_with_explanation(
        self,
        features: dict,
        jurisdiction: str = 'EU_AI_ACT',
        consent_token: str = None
    ):
        """
        Make prediction with mandatory explanation for high-risk inferences
        """
        # Make prediction
        instances = [{'features': list(features.values())}]
        prediction = self.endpoint.predict(instances=instances)
        
        confidence = prediction.predictions[0]['confidence']
        value = prediction.predictions[0]['value']
        
        # Check if high-risk
        if confidence > self.high_risk_threshold:
            # Generate SHAP explanation
            if self.explainer is None:
                self._initialize_explainer()
            
            input_array = np.array([list(features.values())])
            shap_values = self.explainer.shap_values(input_array)
            
            # Create explanation
            explanation = {
                'shap_values': shap_values.tolist(),
                'feature_importance': dict(zip(features.keys(), shap_values[0])),
                'base_value': float(self.explainer.expected_value),
                'confidence_score': confidence
            }
            
            # Validate with SovereignGuardrail
            try:
                self.guardrail.validate_action(
                    action_type='High_Risk_Inference',
                    payload={
                        'inference': 'outbreak_prediction',
                        'confidence_score': confidence,
                        'explanation': explanation,
                        'evidence_chain': list(features.keys()),
                        'consent_token': consent_token,
                        'consent_scope': 'diagnosis'
                    },
                    jurisdiction=jurisdiction
                )
            except SovereigntyViolationError as e:
                raise ValueError(f"High-risk inference rejected: {e}")
            
            return {
                'prediction': value,
                'confidence': confidence,
                'explanation': explanation,
                'high_risk': True
            }
        
        else:
            # Low-risk prediction (no explanation required)
            return {
                'prediction': value,
                'confidence': confidence,
                'high_risk': False
            }
    
    def _initialize_explainer(self):
        """Initialize SHAP explainer with background data"""
        # Load background data from BigQuery
        background_data = self._load_background_data()
        
        def predict_fn(X):
            instances = [{'features': x.tolist()} for x in X]
            predictions = self.endpoint.predict(instances=instances)
            return np.array([p['value'] for p in predictions.predictions])
        
        self.explainer = shap.KernelExplainer(predict_fn, background_data)
    
    def _load_background_data(self):
        """Load representative background data for SHAP"""
        from google.cloud import bigquery
        
        client = bigquery.Client()
        query = """
            SELECT temperature, rainfall, population_density, previous_cases
            FROM `iluminara.outbreak_data`
            ORDER BY RAND()
            LIMIT 100
        """
        
        df = client.query(query).to_dataframe()
        return df.values


# Usage
explainer = ExplainableVertexAI(
    endpoint_id='1234567890',
    project='your-project-id',
    location='us-central1'
)

# Make prediction with explanation
result = explainer.predict_with_explanation(
    features={
        'temperature': 32.5,
        'rainfall': 120.0,
        'population_density': 5000,
        'previous_cases': 15
    },
    jurisdiction='EU_AI_ACT',
    consent_token='VALID_CONSENT_TOKEN'
)

if result['high_risk']:
    print(f"üö® HIGH-RISK PREDICTION: {result['prediction']}")
    print(f"üìä Confidence: {result['confidence']:.2%}")
    print(f"üîç Feature Importance:")
    for feature, importance in result['explanation']['feature_importance'].items():
        print(f"   {feature}: {importance:.4f}")
else:
    print(f"‚úÖ Low-risk prediction: {result['prediction']}")
```

## Hierarchical forecasting

Vertex AI supports hierarchical forecasting for spatial consistency:

```python
# Train hierarchical model
job = aiplatform.AutoMLForecastingTrainingJob(
    display_name='hierarchical-forecast',
    optimization_objective='minimize-rmse',
    hierarchy_config={
        'group_columns': ['country', 'region', 'district', 'community'],
        'group_total_weight': 1.0,
        'temporal_total_weight': 0.0,
        'group_temporal_total_weight': 0.0
    }
)

# Forecasts are spatially consistent:
# Community (Ifo Camp)  ‚Üí [18, 22, 27]
# District (Dadaab)     ‚Üí [55, 68, 82]
# Region (Garissa)      ‚Üí [145, 175, 210]
# National (Kenya)      ‚Üí [550, 680, 820]
```

## Compliance validation

Every high-risk inference is validated against multiple frameworks:

```python
# EU AI Act ¬ß6 (High-Risk AI)
guardrail.validate_action(
    action_type='High_Risk_Inference',
    payload={
        'explanation': shap_values,
        'confidence_score': 0.92
    },
    jurisdiction='EU_AI_ACT'
)

# GDPR Art. 22 (Right to Explanation)
guardrail.validate_action(
    action_type='High_Risk_Inference',
    payload={
        'explanation': shap_values,
        'evidence_chain': ['fever', 'diarrhea']
    },
    jurisdiction='GDPR_EU'
)
```

## Performance optimization

### Batch predictions

```python
# Batch predict with explanations
instances = [{'features': f} for f in feature_list]
predictions = endpoint.batch_predict(instances=instances)

# Generate SHAP values in parallel
import concurrent.futures

with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
    shap_results = list(executor.map(
        lambda x: explainer.shap_values(x),
        feature_arrays
    ))
```

### Caching

```python
from functools import lru_cache

@lru_cache(maxsize=1000)
def get_shap_explanation(feature_hash: str):
    """Cache SHAP explanations for identical inputs"""
    return explainer.shap_values(features)
```

## Monitoring

Track explanation quality metrics:

```python
# Prometheus metrics
from prometheus_client import Counter, Histogram

high_risk_inferences = Counter(
    'high_risk_inferences_total',
    'Total high-risk inferences requiring explanation'
)

explanation_latency = Histogram(
    'shap_explanation_latency_seconds',
    'Time to generate SHAP explanation'
)

# Track metrics
high_risk_inferences.inc()
with explanation_latency.time():
    shap_values = explainer.shap_values(features)
```

## Next steps

<CardGroup cols={2}>
  <Card
    title="Deploy to Vertex AI"
    icon="google"
    href="/deployment/gcp"
  >
    Deploy models to production
  </Card>
  <Card
    title="Governance kernel"
    icon="shield-check"
    href="/governance/overview"
  >
    Configure compliance enforcement
  </Card>
  <Card
    title="AI agents"
    icon="brain-circuit"
    href="/ai-agents/overview"
  >
    Integrate with autonomous agents
  </Card>
  <Card
    title="Monitoring"
    icon="chart-line"
    href="/deployment/monitoring"
  >
    Set up metrics and alerts
  </Card>
</CardGroup>
