---
title: Vertex AI + SHAP integration
description: Right to Explanation with explainable AI for high-risk clinical inferences
---

## Overview

iLuminara-Core integrates Google Cloud Vertex AI with SHAP (SHapley Additive exPlanations) to provide the **Right to Explanation** for every high-risk clinical inference, as required by EU AI Act §6 and GDPR Art. 22.

<Card
  title="Compliance"
  icon="scale-balanced"
>
  EU AI Act §6 (High-Risk AI), GDPR Art. 22 (Right to Explanation), ISO 27001 A.18.1.4
</Card>

## Architecture

```
┌─────────────────────────────────────────────────────────┐
│              VERTEX AI FORECASTING                      │
│  ┌──────────────────────────────────────────────────┐  │
│  │  AutoML Time-Series Models                       │  │
│  │  - ARIMA, Prophet, LSTM                          │  │
│  │  - 72-hour outbreak forecasting                  │  │
│  │  - Hierarchical spatial aggregation              │  │
│  └──────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────┘
                         │
                         │ Prediction
                         ▼
┌─────────────────────────────────────────────────────────┐
│              SHAP EXPLAINABILITY ENGINE                 │
│  ┌──────────────────────────────────────────────────┐  │
│  │  TreeExplainer / KernelExplainer                 │  │
│  │  - Feature importance                            │  │
│  │  - SHAP values per prediction                    │  │
│  │  - Confidence intervals                          │  │
│  └──────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────┘
                         │
                         │ Explanation
                         ▼
┌─────────────────────────────────────────────────────────┐
│              SOVEREIGNGUARDRAIL VALIDATION              │
│  - Confidence threshold check (>0.7 = high-risk)       │
│  - Explanation completeness validation                  │
│  - Evidence chain verification                          │
│  - Audit trail logging                                  │
└─────────────────────────────────────────────────────────┘
```

## High-risk inference detection

Any clinical inference with confidence >0.7 is classified as **high-risk** and requires explanation:

```python
from governance_kernel.vector_ledger import SovereignGuardrail, SovereigntyViolationError

guardrail = SovereignGuardrail()

# High-risk inference requires explanation
try:
    guardrail.validate_action(
        action_type='High_Risk_Inference',
        payload={
            'inference': 'cholera_outbreak_predicted',
            'confidence_score': 0.92,  # >0.7 = high-risk
            'explanation': None,  # Missing!
            'evidence_chain': []
        },
        jurisdiction='EU_AI_ACT'
    )
except SovereigntyViolationError as e:
    print(f"❌ {e}")
    # Raises: "High-risk inference requires explanation (EU AI Act §6)"
```

## Vertex AI model training

### Setup

```python
from google.cloud import aiplatform
from google.cloud.aiplatform import gapic as aip

# Initialize Vertex AI
aiplatform.init(
    project='iluminara-core',
    location='us-central1',
    staging_bucket='gs://iluminara-ml-staging'
)

# Create dataset
dataset = aiplatform.TimeSeriesDataset.create(
    display_name='cholera_outbreak_timeseries',
    gcs_source='gs://iluminara-data/cholera_cases.csv',
    bq_source='bq://iluminara-core.health_data.cholera_cases'
)
```

### Train AutoML model

```python
# Train time-series forecasting model
job = aiplatform.AutoMLForecastingTrainingJob(
    display_name='cholera_72h_forecast',
    optimization_objective='minimize-rmse',
    column_specs={
        'date': 'timestamp',
        'cases': 'numeric',
        'location': 'categorical',
        'temperature': 'numeric',
        'rainfall': 'numeric'
    }
)

model = job.run(
    dataset=dataset,
    target_column='cases',
    time_column='date',
    time_series_identifier_column='location',
    forecast_horizon=72,  # 72 hours
    data_granularity_unit='hour',
    data_granularity_count=1,
    budget_milli_node_hours=1000,
    model_display_name='cholera_forecast_v1'
)

print(f"✅ Model trained: {model.resource_name}")
```

### Deploy model

```python
# Deploy to endpoint
endpoint = model.deploy(
    deployed_model_display_name='cholera_forecast_prod',
    machine_type='n1-standard-4',
    min_replica_count=1,
    max_replica_count=10,
    accelerator_type='NVIDIA_TESLA_T4',
    accelerator_count=1
)

print(f"✅ Model deployed: {endpoint.resource_name}")
```

## SHAP explainability

### Generate SHAP values

```python
import shap
import numpy as np
from google.cloud import aiplatform

# Load deployed model
endpoint = aiplatform.Endpoint('projects/123/locations/us-central1/endpoints/456')

# Prepare input data
instances = [{
    'location': 'Dadaab',
    'temperature': 32.5,
    'rainfall': 15.2,
    'population_density': 850,
    'water_quality_index': 0.65,
    'previous_cases': [12, 15, 18, 22, 28]
}]

# Get prediction
prediction = endpoint.predict(instances=instances)
predicted_cases = prediction.predictions[0]['value']
confidence = prediction.predictions[0]['confidence']

print(f"Predicted cases: {predicted_cases}")
print(f"Confidence: {confidence:.2%}")

# Generate SHAP explanation
explainer = shap.KernelExplainer(
    model=lambda x: endpoint.predict(instances=x).predictions,
    data=shap.sample(training_data, 100)  # Background dataset
)

shap_values = explainer.shap_values(instances)

# Extract feature importance
feature_importance = {
    'temperature': shap_values[0][0],
    'rainfall': shap_values[0][1],
    'population_density': shap_values[0][2],
    'water_quality_index': shap_values[0][3],
    'previous_cases': shap_values[0][4]
}

print(f"Feature importance: {feature_importance}")
```

### Validate with SovereignGuardrail

```python
from governance_kernel.vector_ledger import SovereignGuardrail

guardrail = SovereignGuardrail()

# Validate high-risk inference with explanation
guardrail.validate_action(
    action_type='High_Risk_Inference',
    payload={
        'inference': 'cholera_outbreak_predicted',
        'confidence_score': confidence,
        'explanation': {
            'method': 'SHAP',
            'feature_importance': feature_importance,
            'shap_values': shap_values.tolist()
        },
        'evidence_chain': [
            'temperature_anomaly_detected',
            'rainfall_above_threshold',
            'water_quality_degradation',
            'historical_pattern_match'
        ],
        'model_id': model.resource_name,
        'endpoint_id': endpoint.resource_name
    },
    jurisdiction='EU_AI_ACT'
)

print("✅ High-risk inference validated with explanation")
```

## Explanation visualization

### SHAP waterfall plot

```python
import shap
import matplotlib.pyplot as plt

# Create waterfall plot
shap.waterfall_plot(
    shap.Explanation(
        values=shap_values[0],
        base_values=explainer.expected_value,
        data=instances[0],
        feature_names=list(feature_importance.keys())
    )
)

plt.title('SHAP Explanation: Cholera Outbreak Prediction')
plt.savefig('shap_waterfall.png', dpi=300, bbox_inches='tight')
print("✅ SHAP waterfall plot saved")
```

### SHAP force plot

```python
# Create force plot
shap.force_plot(
    base_value=explainer.expected_value,
    shap_values=shap_values[0],
    features=instances[0],
    feature_names=list(feature_importance.keys()),
    matplotlib=True
)

plt.savefig('shap_force.png', dpi=300, bbox_inches='tight')
print("✅ SHAP force plot saved")
```

## Integration with API

### Explainable prediction endpoint

```python
from flask import Flask, request, jsonify
from google.cloud import aiplatform
import shap

app = Flask(__name__)

@app.route('/predict-explainable', methods=['POST'])
def predict_explainable():
    data = request.json
    
    # Get prediction from Vertex AI
    endpoint = aiplatform.Endpoint(data['endpoint_id'])
    prediction = endpoint.predict(instances=[data['features']])
    
    predicted_value = prediction.predictions[0]['value']
    confidence = prediction.predictions[0]['confidence']
    
    # Generate SHAP explanation
    explainer = shap.KernelExplainer(
        model=lambda x: endpoint.predict(instances=x).predictions,
        data=background_data
    )
    shap_values = explainer.shap_values([data['features']])
    
    # Build explanation
    explanation = {
        'method': 'SHAP',
        'feature_importance': dict(zip(
            data['feature_names'],
            shap_values[0].tolist()
        )),
        'confidence_score': confidence
    }
    
    # Validate with SovereignGuardrail
    if confidence > 0.7:
        guardrail = SovereignGuardrail()
        guardrail.validate_action(
            action_type='High_Risk_Inference',
            payload={
                'inference': data['inference_type'],
                'confidence_score': confidence,
                'explanation': explanation,
                'evidence_chain': data.get('evidence_chain', [])
            },
            jurisdiction='EU_AI_ACT'
        )
    
    return jsonify({
        'prediction': predicted_value,
        'confidence': confidence,
        'explanation': explanation,
        'high_risk': confidence > 0.7
    })
```

## Hierarchical forecasting

iLuminara uses hierarchical forecasting to ensure spatial consistency:

```python
from google.cloud import aiplatform

# Train models at multiple spatial scales
scales = [
    ('community', 'Ifo Camp'),
    ('district', 'Dadaab'),
    ('region', 'Garissa'),
    ('national', 'Kenya')
]

models = {}

for scale, location in scales:
    dataset = aiplatform.TimeSeriesDataset.create(
        display_name=f'cholera_{scale}_{location}',
        bq_source=f'bq://iluminara.health_data.cholera_{scale}'
    )
    
    job = aiplatform.AutoMLForecastingTrainingJob(
        display_name=f'cholera_forecast_{scale}',
        optimization_objective='minimize-rmse'
    )
    
    model = job.run(
        dataset=dataset,
        target_column='cases',
        forecast_horizon=72
    )
    
    models[scale] = model
    print(f"✅ {scale} model trained")

# Bottom-up aggregation ensures consistency
# Community forecasts sum to district, district to region, etc.
```

## Performance metrics

### Model evaluation

```python
from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np

# Evaluate model
predictions = model.batch_predict(test_dataset)

mae = mean_absolute_error(y_true, y_pred)
rmse = np.sqrt(mean_squared_error(y_true, y_pred))
mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100

print(f"MAE: {mae:.2f}")
print(f"RMSE: {rmse:.2f}")
print(f"MAPE: {mape:.2f}%")

# Explanation quality metrics
explanation_completeness = len(feature_importance) / len(all_features)
explanation_coverage = sum(abs(v) for v in shap_values[0]) / abs(predicted_value)

print(f"Explanation completeness: {explanation_completeness:.2%}")
print(f"Explanation coverage: {explanation_coverage:.2%}")
```

## Compliance reporting

### Generate explanation report

```python
from datetime import datetime
import json

def generate_explanation_report(prediction, explanation, metadata):
    report = {
        'timestamp': datetime.utcnow().isoformat(),
        'prediction': {
            'value': prediction['value'],
            'confidence': prediction['confidence'],
            'high_risk': prediction['confidence'] > 0.7
        },
        'explanation': {
            'method': 'SHAP',
            'feature_importance': explanation['feature_importance'],
            'top_features': sorted(
                explanation['feature_importance'].items(),
                key=lambda x: abs(x[1]),
                reverse=True
            )[:5]
        },
        'compliance': {
            'framework': 'EU AI Act §6',
            'requirement': 'Right to Explanation',
            'status': 'COMPLIANT'
        },
        'metadata': metadata
    }
    
    # Save to audit trail
    with open(f'explanations/{metadata["prediction_id"]}.json', 'w') as f:
        json.dump(report, f, indent=2)
    
    return report
```

## Next steps

<CardGroup cols={2}>
  <Card
    title="AI agents"
    icon="brain-circuit"
    href="/ai-agents/overview"
  >
    Deploy autonomous surveillance agents
  </Card>
  <Card
    title="Governance"
    icon="shield-check"
    href="/governance/overview"
  >
    Configure SovereignGuardrail
  </Card>
  <Card
    title="Deployment"
    icon="rocket"
    href="/deployment/gcp"
  >
    Deploy to Google Cloud Platform
  </Card>
  <Card
    title="API reference"
    icon="terminal"
    href="/api-reference/overview"
  >
    Integrate with REST API
  </Card>
</CardGroup>
