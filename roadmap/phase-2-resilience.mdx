---
title: 'Phase 2: Data Fault Tolerance'
description: 'Event-driven architecture for the Golden Thread'
icon: 'network-wired'
---

## Objective

Ensure the "Golden Thread" of health data never snaps, even during internet blackouts, regional failures, or infrastructure attacks.

<Card
  title="Strategic imperative"
  icon="link"
>
  "In a refugee camp, the internet is a luxury. The Golden Thread must flow even in digital darkness."
</Card>

## Current architecture (Fragile)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         EDGE NODE (Dadaab)          â”‚
â”‚  - Collects health data             â”‚
â”‚  - Requires internet for sync       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”‚ âŒ Internet required
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         CLOUD ORACLE (GCP)          â”‚
â”‚  - BigQuery analytics               â”‚
â”‚  - Vertex AI forecasting            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Problems:**
- âŒ Internet blackout = data loss
- âŒ Cloud region failure = complete outage
- âŒ Synchronous processing = slow response
- âŒ No conflict resolution for diverging timelines

## Target architecture (Resilient)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         EDGE NODE (Dadaab)          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Local Kafka Buffer          â”‚  â”‚
â”‚  â”‚  - 7 days disk storage       â”‚  â”‚
â”‚  â”‚  - Offline operation         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”‚ âœ… Async sync when online
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              KAFKA EVENT BUS (Golden Thread)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   AFRICA     â”‚  â”‚   EUROPE     â”‚  â”‚   AMERICAS   â”‚     â”‚
â”‚  â”‚   (Primary)  â”‚  â”‚   (Replica)  â”‚  â”‚   (Replica)  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”‚ âœ… Active-active replication
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         CLOUD ORACLE (Multi-Cloud)  â”‚
â”‚  - BigQuery analytics               â”‚
â”‚  - Vertex AI forecasting            â”‚
â”‚  - Automatic failover               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Benefits:**
- âœ… 7-day offline buffer (no data loss)
- âœ… Multi-region replication (no single point of failure)
- âœ… Asynchronous processing (fast response)
- âœ… Conflict resolution (diverging timelines merge)

## Architecture upgrades

### 1. Apache Kafka integration

Event-driven architecture with local disk buffering for edge nodes.

**Kafka topics:**
```
iluminara.cbs.raw          # Community-based surveillance
iluminara.emr.raw          # Electronic medical records
iluminara.idsr.raw         # Integrated Disease Surveillance Response
iluminara.golden_thread    # Fused verified timeline
iluminara.alerts           # Real-time outbreak alerts
```

**Edge node producer:**
```python
from kafka import KafkaProducer
import json

producer = KafkaProducer(
    bootstrap_servers=['kafka-africa.iluminara.health:9092'],
    value_serializer=lambda v: json.dumps(v).encode('utf-8'),
    # Offline buffer configuration
    buffer_memory=33554432,  # 32MB local buffer
    max_block_ms=7*24*60*60*1000,  # 7 days
    retries=999999,  # Infinite retries
    acks='all'  # Wait for all replicas
)

# Send CBS signal
producer.send('iluminara.cbs.raw', {
    'patient_id': 'PAT_12345',
    'location': 'Dadaab',
    'symptom': 'diarrhea',
    'timestamp': '2025-12-25T10:00:00Z',
    'source': 'CHV_AMINA_HASSAN'
})

# Flush to disk (survives power loss)
producer.flush()
```

**Cloud consumer (Golden Thread):**
```python
from kafka import KafkaConsumer
from edge_node.sync_protocol.golden_thread import GoldenThread

consumer = KafkaConsumer(
    'iluminara.cbs.raw',
    'iluminara.emr.raw',
    bootstrap_servers=['kafka-africa.iluminara.health:9092'],
    group_id='golden-thread-processor',
    auto_offset_reset='earliest'
)

gt = GoldenThread()

for message in consumer:
    data = json.loads(message.value)
    
    # Fuse data streams
    fused = gt.fuse_data_streams(
        cbs_signal=data if message.topic == 'iluminara.cbs.raw' else None,
        emr_record=data if message.topic == 'iluminara.emr.raw' else None,
        patient_id=data['patient_id']
    )
    
    # Publish to golden thread
    producer.send('iluminara.golden_thread', fused.to_dict())
```

### 2. Active-active replication

Multi-region Kafka clusters with bidirectional replication.

**Cluster topology:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   KAFKA CLUSTER (Africa)            â”‚
â”‚   - 3 brokers                       â”‚
â”‚   - Replication factor: 3           â”‚
â”‚   - Min in-sync replicas: 2         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”‚ âœ… Bidirectional replication
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   KAFKA CLUSTER (Europe)            â”‚
â”‚   - 3 brokers                       â”‚
â”‚   - Replication factor: 3           â”‚
â”‚   - Min in-sync replicas: 2         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”‚ âœ… Bidirectional replication
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   KAFKA CLUSTER (Americas)          â”‚
â”‚   - 3 brokers                       â”‚
â”‚   - Replication factor: 3           â”‚
â”‚   - Min in-sync replicas: 2         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**MirrorMaker 2 configuration:**
```properties
# mm2.properties

# Source cluster (Africa)
clusters = africa, europe, americas

africa.bootstrap.servers = kafka-africa.iluminara.health:9092
europe.bootstrap.servers = kafka-europe.iluminara.health:9092
americas.bootstrap.servers = kafka-americas.iluminara.health:9092

# Replication flows
africa->europe.enabled = true
africa->americas.enabled = true
europe->africa.enabled = true
europe->americas.enabled = true
americas->africa.enabled = true
americas->europe.enabled = true

# Topics to replicate
africa->europe.topics = iluminara.*
africa->americas.topics = iluminara.*

# Conflict resolution
replication.policy.class = org.apache.kafka.connect.mirror.IdentityReplicationPolicy
```

### 3. Conflict resolution

When edge nodes reconnect after offline periods, conflicts may arise. The Golden Thread uses vector clocks for conflict resolution.

**Conflict detection:**
```python
from typing import Dict, List
from datetime import datetime

class VectorClock:
    def __init__(self):
        self.clock: Dict[str, int] = {}
    
    def increment(self, node_id: str):
        self.clock[node_id] = self.clock.get(node_id, 0) + 1
    
    def merge(self, other: 'VectorClock') -> 'VectorClock':
        merged = VectorClock()
        all_nodes = set(self.clock.keys()) | set(other.clock.keys())
        
        for node in all_nodes:
            merged.clock[node] = max(
                self.clock.get(node, 0),
                other.clock.get(node, 0)
            )
        
        return merged
    
    def happens_before(self, other: 'VectorClock') -> bool:
        """Check if this event happened before other"""
        return (
            all(self.clock.get(k, 0) <= other.clock.get(k, 0) for k in self.clock)
            and any(self.clock.get(k, 0) < other.clock.get(k, 0) for k in self.clock)
        )
    
    def concurrent(self, other: 'VectorClock') -> bool:
        """Check if events are concurrent (conflict)"""
        return not self.happens_before(other) and not other.happens_before(self)
```

**Conflict resolution strategies:**

<AccordionGroup>
  <Accordion title="Last-Write-Wins (LWW)">
    Use timestamp to determine winner. Simple but may lose data.
    
    ```python
    def resolve_lww(record_a, record_b):
        if record_a['timestamp'] > record_b['timestamp']:
            return record_a
        return record_b
    ```
  </Accordion>
  
  <Accordion title="Semantic merge">
    Merge non-conflicting fields, flag conflicts for human review.
    
    ```python
    def resolve_semantic(record_a, record_b):
        merged = {}
        conflicts = []
        
        for key in set(record_a.keys()) | set(record_b.keys()):
            if key not in record_a:
                merged[key] = record_b[key]
            elif key not in record_b:
                merged[key] = record_a[key]
            elif record_a[key] == record_b[key]:
                merged[key] = record_a[key]
            else:
                # Conflict detected
                conflicts.append({
                    'field': key,
                    'value_a': record_a[key],
                    'value_b': record_b[key]
                })
                # Use most severe value for health data
                merged[key] = max(record_a[key], record_b[key])
        
        return merged, conflicts
    ```
  </Accordion>
  
  <Accordion title="CRDT (Conflict-free Replicated Data Type)">
    Use mathematical structures that guarantee convergence.
    
    ```python
    class GCounter:
        """Grow-only counter (CRDT)"""
        def __init__(self):
            self.counts: Dict[str, int] = {}
        
        def increment(self, node_id: str):
            self.counts[node_id] = self.counts.get(node_id, 0) + 1
        
        def merge(self, other: 'GCounter'):
            for node_id, count in other.counts.items():
                self.counts[node_id] = max(
                    self.counts.get(node_id, 0),
                    count
                )
        
        def value(self) -> int:
            return sum(self.counts.values())
    ```
  </Accordion>
</AccordionGroup>

### 4. Disaster recovery

Automated DNS failover via Cloudflare API to redirect traffic instantly if a primary region's health check fails.

**Health check configuration:**
```python
import requests
from datetime import datetime

class HealthMonitor:
    def __init__(self, regions: List[str]):
        self.regions = regions
        self.health_status = {}
    
    def check_region(self, region: str) -> bool:
        """Check if region is healthy"""
        try:
            response = requests.get(
                f'https://kafka-{region}.iluminara.health/health',
                timeout=5
            )
            return response.status_code == 200
        except:
            return False
    
    def monitor(self):
        """Continuous health monitoring"""
        for region in self.regions:
            is_healthy = self.check_region(region)
            
            if not is_healthy and self.health_status.get(region, True):
                # Region just failed - trigger failover
                self.failover(region)
            
            self.health_status[region] = is_healthy
    
    def failover(self, failed_region: str):
        """Automatic failover to backup region"""
        backup_region = self.get_backup_region(failed_region)
        
        # Update Cloudflare DNS
        self.update_dns(failed_region, backup_region)
        
        # Alert operations team
        self.send_alert(f'ðŸš¨ FAILOVER: {failed_region} â†’ {backup_region}')
    
    def update_dns(self, failed_region: str, backup_region: str):
        """Update DNS to point to backup region"""
        cloudflare_api = 'https://api.cloudflare.com/client/v4'
        
        # Update A record
        requests.patch(
            f'{cloudflare_api}/zones/{ZONE_ID}/dns_records/{RECORD_ID}',
            headers={'Authorization': f'Bearer {CLOUDFLARE_TOKEN}'},
            json={
                'content': self.get_region_ip(backup_region),
                'comment': f'Failover from {failed_region} at {datetime.utcnow()}'
            }
        )
```

**Failover SLA:**
- Detection: <30 seconds
- DNS propagation: <60 seconds
- Total failover time: <90 seconds
- Data loss: 0 (all data replicated)

### 5. Offline buffer management

Edge nodes maintain 7-day local buffer for offline operation.

**Buffer configuration:**
```python
# edge_node/config.py

KAFKA_CONFIG = {
    'bootstrap_servers': ['kafka-africa.iluminara.health:9092'],
    
    # Offline buffer
    'buffer_memory': 33554432,  # 32MB RAM buffer
    'max_block_ms': 7*24*60*60*1000,  # 7 days
    
    # Disk persistence
    'log_dir': '/var/iluminara/kafka-buffer',
    'log_retention_hours': 168,  # 7 days
    'log_segment_bytes': 1073741824,  # 1GB segments
    
    # Reliability
    'retries': 999999,  # Infinite retries
    'acks': 'all',  # Wait for all replicas
    'enable_idempotence': True,  # Exactly-once semantics
}
```

**Buffer monitoring:**
```bash
# Check buffer status
./scripts/check_kafka_buffer.sh

# Output:
# ðŸ“Š Kafka Buffer Status
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Buffer size:        2.3 GB / 32 GB (7%)
# Messages queued:    45,231
# Oldest message:     2 days ago
# Sync status:        âœ… ONLINE
# Last sync:          5 minutes ago
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

## Performance benchmarks

| Metric | Before (Synchronous) | After (Event-Driven) |
|--------|---------------------|----------------------|
| **API latency** | 450ms | 45ms (10x faster) |
| **Throughput** | 100 req/s | 10,000 req/s (100x) |
| **Offline capability** | 0 hours | 168 hours (7 days) |
| **Data loss (region failure)** | 100% | 0% |
| **Failover time** | Manual (hours) | Automatic (<90s) |

## Success metrics

<AccordionGroup>
  <Accordion title="Uptime">
    - âœ… 99.99% uptime (Golden Thread)
    - âœ… <90 seconds failover time
    - âœ… Zero data loss during regional failure
  </Accordion>
  <Accordion title="Performance">
    - âœ… <100ms cross-region latency
    - âœ… 10,000+ messages/second throughput
    - âœ… 7-day offline buffer capacity
  </Accordion>
  <Accordion title="Resilience">
    - âœ… Survive internet blackout (7 days)
    - âœ… Survive cloud region failure (instant failover)
    - âœ… Survive edge node power loss (disk persistence)
  </Accordion>
</AccordionGroup>

## Next steps

<CardGroup cols={2}>
  <Card
    title="Phase 3: Security"
    icon="shield-halved"
    href="/roadmap/phase-3-security"
  >
    Quantum-hardened cryptography and biometrics
  </Card>
  <Card
    title="Kafka setup"
    icon="stream"
    href="/deployment/kafka"
  >
    Event bus configuration guide
  </Card>
  <Card
    title="Conflict resolution"
    icon="code-merge"
    href="/architecture/conflict-resolution"
  >
    Vector clocks and CRDT implementation
  </Card>
  <Card
    title="Disaster recovery"
    icon="life-ring"
    href="/deployment/disaster-recovery"
  >
    Failover and backup procedures
  </Card>
</CardGroup>
