---
title: Vertex AI + SHAP integration
description: Right to Explanation enforcement with explainable AI for high-risk clinical inferences
---

## Overview

iLuminara-Core integrates Google Cloud Vertex AI with SHAP (SHapley Additive exPlanations) to provide **Right to Explanation** for every high-risk clinical inference, ensuring compliance with EU AI Act ยง6 and GDPR Art. 22.

<Card
  title="Philosophy"
  icon="brain-circuit"
>
  "Every clinical decision with consequence must be explicable."
</Card>

## Compliance requirements

### EU AI Act ยง6 - High-Risk AI Systems

High-risk AI systems in healthcare require:
- **Explainability** - SHAP values for every prediction
- **Human oversight** - Clinical validation required
- **Transparency** - Feature importance disclosed
- **Auditability** - Complete decision trail

### GDPR Art. 22 - Automated Decision-Making

Individuals have the right to:
- **Explanation** of automated decisions
- **Human intervention** in the decision process
- **Contest** the decision
- **Obtain** human review

## Next steps

<CardGroup cols={2}>
  <Card
    title="Governance kernel"
    icon="shield-check"
    href="/governance/overview"
  >
    Understand compliance enforcement
  </Card>
  <Card
    title="AI agents"
    icon="brain-circuit"
    href="/ai-agents/overview"
  >
    Deploy autonomous surveillance
  </Card>
</CardGroup>
