---
title: Vertex AI + SHAP integration
description: Right to Explanation with explainable AI for high-risk clinical inferences
---

## Overview

The Vertex AI + SHAP integration ensures every high-risk clinical inference includes full explainability, meeting EU AI Act §6 and GDPR Art. 22 requirements.

<Card
  title="Compliance"
  icon="scale-balanced"
>
  EU AI Act §6 (High-Risk AI), GDPR Art. 22 (Right to Explanation), HIPAA §164.524 (Right of Access)
</Card>

## Right to Explanation

Every prediction with confidence > 0.7 automatically includes:

<Steps>
  <Step title="Confidence score">
    Numerical confidence in the prediction (0.0 - 1.0)
  </Step>
  <Step title="SHAP values">
    Feature-level contribution to the prediction
  </Step>
  <Step title="Evidence chain">
    Top 3 most important features with their impact
  </Step>
  <Step title="Decision rationale">
    Human-readable explanation of the decision
  </Step>
</Steps>

## Basic usage

```python
from cloud_oracle.vertex_ai_shap import VertexAIExplainer

# Initialize explainer
explainer = VertexAIExplainer(
    project_id="iluminara-core",
    location="us-central1",
    model_name="outbreak-forecaster",
    enable_audit=True
)

# Make prediction with explanation
features = {
    "case_count": 45.0,
    "attack_rate": 0.04,
    "r_effective": 2.8,
    "population_density": 15000.0,
    "water_quality_index": 0.3,
    "sanitation_coverage": 0.45,
    "temperature_celsius": 28.5,
    "rainfall_mm": 120.0
}

result = explainer.predict_with_explanation(
    features=features,
    patient_id="PAT_12345",
    jurisdiction="KDPA_KE"
)

# Check compliance
if result['compliant']:
    print("✅ COMPLIANT: Explanation meets EU AI Act §6 requirements")
else:
    print("❌ NON-COMPLIANT: High-risk AI without explanation")
```

## Response structure

```json
{
  "prediction": 0.85,
  "confidence": 0.92,
  "risk_level": "critical",
  "shap_values": {
    "case_count": 0.234,
    "attack_rate": 0.189,
    "r_effective": 0.156,
    "water_quality_index": -0.089
  },
  "feature_importance": {
    "case_count": 0.234,
    "attack_rate": 0.189,
    "r_effective": 0.156
  },
  "evidence_chain": [
    "case_count=45.00 increases risk (SHAP: +0.234)",
    "attack_rate=0.04 increases risk (SHAP: +0.189)",
    "r_effective=2.80 increases risk (SHAP: +0.156)"
  ],
  "decision_rationale": "Prediction: 0.85 with 92.0% confidence. Primary driver: case_count (importance: 0.234). Decision based on 8 features.",
  "compliant": true,
  "timestamp": "2025-12-25T10:00:00.000Z"
}
```

## Risk levels

| Level | Confidence Range | Explanation Required |
|-------|------------------|---------------------|
| **LOW** | 0.0 - 0.5 | Optional |
| **MEDIUM** | 0.5 - 0.7 | Recommended |
| **HIGH** | 0.7 - 0.9 | Required |
| **CRITICAL** | 0.9 - 1.0 | Required + Audit |

## SHAP explanation

SHAP (SHapley Additive exPlanations) provides feature-level attribution:

```python
# Visualize explanation
print(explainer.visualize_explanation(result))
```

**Output:**
```
============================================================
SHAP EXPLANATION (Right to Explanation - GDPR Art. 22)
============================================================
Prediction: 0.85
Confidence: 92.0%
Risk Level: CRITICAL

Feature Importance:
------------------------------------------------------------
case_count           ██████████████████████████ 0.234
attack_rate          ███████████████████ 0.189
r_effective          ████████████████ 0.156
population_density   ████████ 0.089
water_quality_index  ████ 0.045

Evidence Chain:
------------------------------------------------------------
1. case_count=45.00 increases risk (SHAP: +0.234)
2. attack_rate=0.04 increases risk (SHAP: +0.189)
3. r_effective=2.80 increases risk (SHAP: +0.156)

Decision Rationale:
------------------------------------------------------------
Prediction: 0.85 with 92.0% confidence. Primary driver: 
case_count (importance: 0.234). Decision based on 8 features.
============================================================
```

## Batch predictions

Process multiple predictions with explanations:

```python
features_list = [
    {"case_count": 45.0, "attack_rate": 0.04, ...},
    {"case_count": 12.0, "attack_rate": 0.01, ...},
    {"case_count": 78.0, "attack_rate": 0.06, ...}
]

patient_ids = ["PAT_001", "PAT_002", "PAT_003"]

results = explainer.batch_predict_with_explanations(
    features_list=features_list,
    patient_ids=patient_ids,
    jurisdiction="KDPA_KE"
)

for result in results:
    print(f"Patient: {result['patient_id']}, Risk: {result['risk_level']}")
```

## Audit trail

All explanations are automatically logged to BigQuery:

```sql
SELECT 
  timestamp,
  patient_id,
  prediction,
  confidence,
  risk_level,
  decision_rationale,
  compliant
FROM `iluminara-core.iluminara_audit.ai_explanations`
WHERE risk_level IN ('HIGH', 'CRITICAL')
ORDER BY timestamp DESC
LIMIT 100
```

## Compliance validation

The system automatically validates compliance:

```python
def _check_compliance(risk_level, shap_values):
    """
    High-risk AI (confidence > 0.7) requires full explanation.
    """
    if risk_level in [RiskLevel.HIGH, RiskLevel.CRITICAL]:
        if not shap_values or len(shap_values) == 0:
            logger.error("❌ Compliance violation: High-risk AI without explanation")
            return False
    return True
```

## Integration with SovereignGuardrail

All AI inferences are validated against sovereignty constraints:

```python
from governance_kernel.vector_ledger import SovereignGuardrail

guardrail = SovereignGuardrail()

# Validate high-risk inference
guardrail.validate_action(
    action_type='High_Risk_Inference',
    payload={
        'inference': 'outbreak_prediction',
        'explanation': result['shap_values'],
        'confidence_score': result['confidence'],
        'evidence_chain': result['evidence_chain']
    },
    jurisdiction='GDPR_EU'
)
```

## Model deployment

Deploy your model to Vertex AI:

```bash
# Train model
python cloud_oracle/train_outbreak_model.py

# Deploy to Vertex AI
gcloud ai models upload \
  --region=us-central1 \
  --display-name=outbreak-forecaster \
  --container-image-uri=gcr.io/iluminara-core/outbreak-model:latest

# Create endpoint
gcloud ai endpoints create \
  --region=us-central1 \
  --display-name=outbreak-forecaster-endpoint

# Deploy model to endpoint
gcloud ai endpoints deploy-model ENDPOINT_ID \
  --region=us-central1 \
  --model=MODEL_ID \
  --display-name=outbreak-forecaster-v1
```

## Testing

Test the explainer:

```bash
python cloud_oracle/vertex_ai_shap.py
```

## Next steps

<CardGroup cols={2}>
  <Card
    title="Bio-Interface API"
    icon="mobile"
    href="/integrations/bio-interface"
  >
    Mobile health app integration
  </Card>
  <Card
    title="Governance kernel"
    icon="shield-check"
    href="/governance/overview"
  >
    Compliance enforcement
  </Card>
  <Card
    title="AI agents"
    icon="brain-circuit"
    href="/ai-agents/overview"
  >
    Autonomous surveillance
  </Card>
  <Card
    title="Deployment"
    icon="rocket"
    href="/deployment/gcp"
  >
    Deploy to Google Cloud
  </Card>
</CardGroup>
