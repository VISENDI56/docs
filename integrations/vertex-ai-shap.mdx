---
title: Vertex AI + SHAP integration
description: Right to Explanation for high-risk clinical AI inferences
---

## Overview

Every high-risk clinical inference (confidence > 0.7) automatically triggers SHAP analysis to comply with EU AI Act §6 and GDPR Art. 22.

<Card
  title="Compliance"
  icon="scale-balanced"
>
  EU AI Act §6 (High-Risk AI) + GDPR Art. 22 (Right to Explanation)
</Card>

## Architecture

```
┌─────────────────────────────────────┐
│      MOBILE HEALTH APP              │
│  - Symptom collection               │
│  - Patient data                     │
└─────────────────────────────────────┘
              │
              ▼
┌─────────────────────────────────────┐
│      VERTEX AI ENDPOINT             │
│  - Model prediction                 │
│  - Confidence scoring               │
└─────────────────────────────────────┘
              │
              ▼ (if confidence > 0.7)
┌─────────────────────────────────────┐
│      SHAP EXPLAINER                 │
│  - Feature contributions            │
│  - Decision rationale               │
│  - Evidence chain                   │
└─────────────────────────────────────┘
              │
              ▼
┌─────────────────────────────────────┐
│      CLINICAL REVIEW                │
│  - Human-readable report            │
│  - Compliance attestation           │
└─────────────────────────────────────┘
```

## Basic usage

```python
from integrations.vertex_ai_shap import VertexAIExplainer

# Initialize explainer
explainer = VertexAIExplainer(
    project_id="iluminara-health",
    location="us-central1",
    high_risk_threshold=0.7
)

# Example: Malaria diagnosis prediction
instances = [
    {
        "fever": 1.0,
        "chills": 1.0,
        "headache": 0.8,
        "nausea": 0.6,
        "fatigue": 0.9,
        "age": 35,
        "location_risk": 0.7
    }
]

feature_names = ["fever", "chills", "headache", "nausea", "fatigue", "age", "location_risk"]

# Make prediction with automatic explanation
result = explainer.predict_with_explanation(
    endpoint_id="projects/123/locations/us-central1/endpoints/456",
    instances=instances,
    feature_names=feature_names
)

# Check compliance
print(f"High-Risk: {result['high_risk']}")
print(f"Compliance: {result['compliance_status']}")
```

## Response format

```json
{
  "predictions": [0.92],
  "confidence_scores": [0.92],
  "high_risk": true,
  "compliance_status": "COMPLIANT",
  "explanations": [
    {
      "instance_id": 0,
      "feature_contributions": {
        "fever": 0.25,
        "chills": 0.18,
        "location_risk": 0.15,
        "fatigue": 0.12,
        "headache": 0.10,
        "nausea": 0.08,
        "age": 0.04
      },
      "base_value": 0.15,
      "prediction": 0.92,
      "top_features": [
        ["fever", 0.25],
        ["chills", 0.18],
        ["location_risk", 0.15],
        ["fatigue", 0.12],
        ["headache", 0.10]
      ]
    }
  ],
  "timestamp": "2025-12-26T10:00:00.000Z"
}
```

## High-risk threshold

The system automatically triggers SHAP explanation when confidence exceeds the threshold:

| Threshold | Description | Use Case |
|-----------|-------------|----------|
| 0.5 | Low threshold | Research, non-critical decisions |
| 0.7 | Standard (default) | Clinical decision support |
| 0.9 | High threshold | Life-critical interventions |

```python
# Configure threshold
explainer = VertexAIExplainer(
    project_id="iluminara-health",
    high_risk_threshold=0.9  # Only explain very high confidence
)
```

## Clinical explanation report

Generate human-readable reports for clinical review:

```python
# Generate report
report = explainer.generate_explanation_report(
    result=result,
    patient_id="PAT_12345"
)

print(report)
```

**Output:**

```
============================================================
CLINICAL AI EXPLANATION REPORT
============================================================

Patient ID: PAT_12345
Timestamp: 2025-12-26T10:00:00.000Z
High-Risk Inference: YES
Compliance Status: COMPLIANT

PREDICTIONS:
  Instance 0: 0.92 (confidence: 92.00%)

FEATURE CONTRIBUTIONS (SHAP Analysis):

  Instance 0:
    Base Value: 0.1500
    Prediction: 0.9200

    Top Contributing Features:
      ↑ fever: +0.2500
      ↑ chills: +0.1800
      ↑ location_risk: +0.1500
      ↑ fatigue: +0.1200
      ↑ headache: +0.1000

============================================================
COMPLIANCE ATTESTATION:
  ✓ EU AI Act §6 (High-Risk AI Systems)
  ✓ GDPR Art. 22 (Right to Explanation)
  ✓ HIPAA §164.312(b) (Audit Controls)
============================================================
```

## Compliance validation

Validate that explanations meet regulatory requirements:

```python
# Validate explanation
is_compliant, missing_fields = explainer.validate_explanation_compliance(
    explanation=result['explanations'][0]
)

if is_compliant:
    print("✅ Explanation meets compliance requirements")
else:
    print(f"❌ Missing fields: {missing_fields}")
```

## Integration with SovereignGuardrail

All predictions are validated against sovereignty constraints:

```python
from governance_kernel.vector_ledger import SovereignGuardrail

guardrail = SovereignGuardrail()

# Validate high-risk inference
guardrail.validate_action(
    action_type='High_Risk_Inference',
    payload={
        'explanation': result['explanations'][0],
        'confidence_score': result['confidence_scores'][0],
        'evidence_chain': result['explanations'][0]['top_features'],
        'consent_token': 'VALID_TOKEN',
        'consent_scope': 'diagnosis'
    },
    jurisdiction='EU_AI_ACT'
)
```

## Audit trail

All high-risk inferences are automatically logged:

```python
# View audit log
for entry in explainer.audit_log:
    print(f"{entry['timestamp']}: {entry['compliance_status']}")
```

**Audit log format:**

```json
{
  "timestamp": "2025-12-26T10:00:00.000Z",
  "endpoint_id": "projects/123/locations/us-central1/endpoints/456",
  "confidence": 0.92,
  "high_risk": true,
  "compliance_status": "COMPLIANT",
  "framework": "EU_AI_ACT_6"
}
```

## Deployment

### Install dependencies

```bash
pip install shap google-cloud-aiplatform numpy
```

### Configure Vertex AI

```bash
# Set project
export GOOGLE_CLOUD_PROJECT=iluminara-health

# Authenticate
gcloud auth application-default login

# Enable Vertex AI API
gcloud services enable aiplatform.googleapis.com
```

### Deploy model to Vertex AI

```bash
# Upload model
gcloud ai models upload \
  --region=us-central1 \
  --display-name=malaria-classifier \
  --artifact-uri=gs://iluminara-models/malaria-v1

# Create endpoint
gcloud ai endpoints create \
  --region=us-central1 \
  --display-name=malaria-endpoint

# Deploy model to endpoint
gcloud ai endpoints deploy-model ENDPOINT_ID \
  --region=us-central1 \
  --model=MODEL_ID \
  --display-name=malaria-deployment
```

## Performance considerations

- **SHAP calculation**: ~2-5 seconds per instance
- **Background data**: Use 100-500 samples for KernelExplainer
- **Caching**: Cache SHAP explainer for repeated predictions
- **Batch processing**: Process multiple instances together

## Next steps

<CardGroup cols={2}>
  <Card
    title="Bio-Interface API"
    icon="mobile"
    href="/integrations/bio-interface"
  >
    Integrate with mobile health apps
  </Card>
  <Card
    title="Governance kernel"
    icon="shield-check"
    href="/governance/overview"
  >
    Configure compliance enforcement
  </Card>
  <Card
    title="Golden Thread"
    icon="link"
    href="/architecture/golden-thread"
  >
    Fuse CBS and EMR data streams
  </Card>
  <Card
    title="Deployment"
    icon="rocket"
    href="/deployment/gcp"
  >
    Deploy to Google Cloud Platform
  </Card>
</CardGroup>
