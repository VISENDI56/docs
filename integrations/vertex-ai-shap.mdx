---
title: Vertex AI + SHAP integration
description: Right to Explanation with explainable AI for high-risk clinical inferences
---

## Overview

Every high-risk clinical inference in iLuminara-Core requires explainability to comply with the EU AI Act Â§6 and GDPR Art. 22. This integration combines Google Cloud Vertex AI with SHAP (SHapley Additive exPlanations) to provide transparent, auditable AI decisions.

<Card
  title="Compliance"
  icon="scale-balanced"
>
  EU AI Act Â§6 (High-Risk AI) + GDPR Art. 22 (Right to Explanation)
</Card>

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      MOBILE APP / CHV DEVICE        â”‚
â”‚  Patient symptoms + vital signs     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      VERTEX AI MODEL                â”‚
â”‚  - Outbreak prediction              â”‚
â”‚  - Disease classification           â”‚
â”‚  - Risk scoring                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼ (if confidence > 0.7)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      SHAP EXPLAINER                 â”‚
â”‚  - Feature contributions            â”‚
â”‚  - Evidence chain                   â”‚
â”‚  - Baseline comparison              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      AUDIT TRAIL (BigQuery)         â”‚
â”‚  - Tamper-proof logging             â”‚
â”‚  - Compliance attestation           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Risk levels

| Level | Confidence | Explainability Required | Use Case |
|-------|-----------|------------------------|----------|
| **LOW** | < 0.5 | No | Routine monitoring |
| **MEDIUM** | 0.5-0.7 | No | Increased surveillance |
| **HIGH** | 0.7-0.9 | **Yes** | Clinical decision support |
| **CRITICAL** | > 0.9 | **Yes** | Emergency response |

## Basic usage

```python
from integrations.vertex_ai_shap import VertexAIExplainer

# Initialize explainer
explainer = VertexAIExplainer(
    project_id="iluminara-core",
    location="us-central1",
    model_name="outbreak-predictor",
    high_risk_threshold=0.7,
    enable_audit=True
)

# Patient features
patient_features = {
    "fever": True,
    "diarrhea": True,
    "vomiting": True,
    "age": 35,
    "location_lat": 0.0512,
    "location_lng": 40.3129,
    "days_since_onset": 2
}

# Get prediction with automatic explanation
result = explainer.predict_with_explanation(
    features=patient_features,
    patient_id="PAT_12345",
    jurisdiction="KDPA_KE"
)

print(f"Prediction: {result['prediction']:.2%}")
print(f"Confidence: {result['confidence']:.2%}")
print(f"Risk Level: {result['risk_level']}")

if result['explanation']:
    print(f"\\nTop Contributing Features:")
    for feature in result['explanation']['top_features']:
        print(f"  - {feature['feature']}: {feature['contribution']:+.2%}")
```

## Response format

### High-risk inference (with explanation)

```json
{
  "prediction": 0.85,
  "confidence": 0.92,
  "risk_level": "critical",
  "explanation": {
    "method": "SHAP",
    "baseline_value": 0.45,
    "feature_contributions": {
      "fever": {
        "value": true,
        "contribution": 0.25,
        "importance": 0.25
      },
      "diarrhea": {
        "value": true,
        "contribution": 0.30,
        "importance": 0.30
      }
    },
    "top_features": [
      {
        "feature": "diarrhea",
        "value": true,
        "contribution": 0.30
      },
      {
        "feature": "fever",
        "value": true,
        "contribution": 0.25
      }
    ],
    "evidence_chain": [
      "diarrhea=true increases risk by 30.00%",
      "fever=true increases risk by 25.00%"
    ]
  },
  "compliance": {
    "eu_ai_act_s6": true,
    "gdpr_art_22": true,
    "explainability_required": true,
    "jurisdiction": "KDPA_KE"
  },
  "metadata": {
    "model_name": "outbreak-predictor",
    "timestamp": "2025-12-25T18:00:00.000Z",
    "patient_id": "PAT_12345"
  }
}
```

## SHAP explanation components

### Feature contributions

Shows how each feature influenced the prediction:

- **Positive contribution** - Increases risk
- **Negative contribution** - Decreases risk
- **Importance** - Absolute magnitude of contribution

### Evidence chain

Human-readable explanation of the decision:

```
"diarrhea=true increases risk by 30.00%"
"fever=true increases risk by 25.00%"
"age=35 decreases risk by 5.00%"
```

### Baseline value

The expected prediction without any patient-specific features. Deviations from baseline are explained by feature contributions.

## Batch prediction

Process multiple patients with explainability:

```python
# Multiple patients
patients = [
    {"fever": True, "cough": True, "age": 45},
    {"diarrhea": True, "vomiting": True, "age": 28},
    {"fever": True, "rash": True, "age": 12}
]

patient_ids = ["PAT_001", "PAT_002", "PAT_003"]

# Batch prediction
results = explainer.batch_predict_with_explanation(
    features_list=patients,
    patient_ids=patient_ids,
    jurisdiction="KDPA_KE"
)

# Process results
for result in results:
    if result['risk_level'] in ['high', 'critical']:
        print(f"ğŸš¨ High-risk patient: {result['metadata']['patient_id']}")
        print(f"   Evidence: {result['explanation']['evidence_chain']}")
```

## Audit trail

All high-risk inferences are automatically logged to BigQuery:

```sql
SELECT
  timestamp,
  patient_id,
  prediction,
  confidence,
  risk_level,
  explanation_provided,
  compliance_eu_ai_act,
  compliance_gdpr_art_22
FROM `iluminara_audit.ai_explanations`
WHERE risk_level IN ('high', 'critical')
ORDER BY timestamp DESC
LIMIT 100
```

## Compliance validation

The explainer automatically validates compliance:

```python
# Compliance check
if result['compliance']['eu_ai_act_s6']:
    print("âœ… EU AI Act Â§6 compliant")

if result['compliance']['gdpr_art_22']:
    print("âœ… GDPR Art. 22 compliant")

if result['compliance']['explainability_required']:
    print("âš ï¸ High-risk inference - Explanation mandatory")
```

## Integration with SovereignGuardrail

All AI inferences are validated against sovereignty constraints:

```python
from governance_kernel.vector_ledger import SovereignGuardrail

guardrail = SovereignGuardrail()

# Validate high-risk inference
guardrail.validate_action(
    action_type='High_Risk_Inference',
    payload={
        'inference': 'diagnosis',
        'explanation': result['explanation'],
        'confidence_score': result['confidence'],
        'evidence_chain': result['explanation']['evidence_chain']
    },
    jurisdiction='GDPR_EU'
)
```

## Deployment

### Local development

```bash
# Install dependencies
pip install shap google-cloud-aiplatform google-cloud-bigquery

# Set environment variables
export GOOGLE_CLOUD_PROJECT=iluminara-core
export GOOGLE_APPLICATION_CREDENTIALS=/path/to/credentials.json

# Run example
python integrations/vertex_ai_shap.py
```

### Production (Cloud Run)

```bash
# Deploy to Cloud Run
gcloud run deploy vertex-ai-explainer \
  --source integrations/ \
  --region us-central1 \
  --allow-unauthenticated \
  --set-env-vars GOOGLE_CLOUD_PROJECT=iluminara-core
```

## Performance considerations

- **SHAP calculation time**: ~100-500ms per inference
- **Batch optimization**: Process multiple patients in parallel
- **Caching**: Cache SHAP explainer for repeated use
- **Async processing**: Use async for non-blocking explanations

## Next steps

<CardGroup cols={2}>
  <Card
    title="Bio-Interface API"
    icon="mobile"
    href="/integrations/bio-interface"
  >
    Integrate with mobile health apps
  </Card>
  <Card
    title="Governance kernel"
    icon="shield-check"
    href="/governance/overview"
  >
    Understand compliance enforcement
  </Card>
  <Card
    title="AI agents"
    icon="brain-circuit"
    href="/ai-agents/overview"
  >
    Deploy autonomous surveillance
  </Card>
  <Card
    title="Audit trail"
    icon="file-contract"
    href="/governance/audit"
  >
    Configure tamper-proof logging
  </Card>
</CardGroup>
