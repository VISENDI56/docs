---
title: Docker deployment
description: Deploy iLuminara components using Docker containers for development and production
---

Docker provides containerized deployment for iLuminara, ensuring consistent environments across development, testing, and production.

## Quick start

### Prerequisites

- Docker Engine 24.0+
- Docker Compose 2.20+
- NVIDIA Container Toolkit (for GPU support)
- 16GB RAM minimum, 32GB recommended
- 100GB disk space

### Basic deployment

```bash
# Clone repository
git clone https://github.com/your-org/iluminara.git
cd iluminara

# Build images
docker-compose build

# Start services
docker-compose up -d

# Check status
docker-compose ps

# View logs
docker-compose logs -f
```

## Docker Compose configuration

### Core services

```yaml docker-compose.yml
version: '3.8'

services:
  # API Gateway
  api-gateway:
    build:
      context: ./services/api-gateway
      dockerfile: Dockerfile
    ports:
      - "8080:8080"
    environment:
      - NODE_ENV=production
      - LOG_LEVEL=info
    depends_on:
      - redis
      - postgres
    networks:
      - iluminara-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # JEPA World Model Service
  jepa-service:
    build:
      context: ./ml_health/jepa
      dockerfile: Dockerfile
    ports:
      - "8081:8081"
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - MODEL_PATH=/models/jepa_world_model.pth
    volumes:
      - ./models:/models:ro
      - ./data:/data
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - iluminara-network
    restart: unless-stopped

  # MPC Controller Service
  mpc-service:
    build:
      context: ./ml_health/mpc
      dockerfile: Dockerfile
    ports:
      - "8082:8082"
    environment:
      - JEPA_SERVICE_URL=http://jepa-service:8081
      - HORIZON=10
      - NUM_ITERATIONS=10
    depends_on:
      - jepa-service
    networks:
      - iluminara-network
    restart: unless-stopped

  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=iluminara
      - POSTGRES_USER=iluminara
      - POSTGRES_PASSWORD=${DB_PASSWORD}
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d
    networks:
      - iluminara-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U iluminara"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis Cache
  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    networks:
      - iluminara-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Prometheus Monitoring
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    networks:
      - iluminara-network
    restart: unless-stopped

  # Grafana Dashboards
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - GF_INSTALL_PLUGINS=grafana-piechart-panel
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    depends_on:
      - prometheus
    networks:
      - iluminara-network
    restart: unless-stopped

volumes:
  postgres-data:
  redis-data:
  prometheus-data:
  grafana-data:

networks:
  iluminara-network:
    driver: bridge
```

### Environment variables

```bash .env
# Database
DB_PASSWORD=your_secure_password_here

# Grafana
GRAFANA_PASSWORD=your_grafana_password

# API Keys
OPENAI_API_KEY=your_openai_key
ANTHROPIC_API_KEY=your_anthropic_key

# NVIDIA
NVIDIA_VISIBLE_DEVICES=all
NVIDIA_DRIVER_CAPABILITIES=compute,utility

# Logging
LOG_LEVEL=info
LOG_FORMAT=json
```

## Service Dockerfiles

### JEPA Service

```dockerfile ml_health/jepa/Dockerfile
FROM nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04

# Install Python
RUN apt-get update && apt-get install -y \
    python3.10 \
    python3-pip \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Copy requirements
COPY requirements.txt .
RUN pip3 install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Expose port
EXPOSE 8081

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
  CMD python3 -c "import requests; requests.get('http://localhost:8081/health')"

# Run service
CMD ["python3", "service.py"]
```

### API Gateway

```dockerfile services/api-gateway/Dockerfile
FROM node:20-alpine

# Set working directory
WORKDIR /app

# Copy package files
COPY package*.json ./

# Install dependencies
RUN npm ci --only=production

# Copy application code
COPY . .

# Build TypeScript
RUN npm run build

# Expose port
EXPOSE 8080

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=30s --retries=3 \
  CMD node healthcheck.js

# Run service
CMD ["node", "dist/index.js"]
```

## GPU support

### NVIDIA Container Toolkit setup

```bash
# Install NVIDIA Container Toolkit
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \
  sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update
sudo apt-get install -y nvidia-container-toolkit

# Restart Docker
sudo systemctl restart docker

# Test GPU access
docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi
```

### GPU resource allocation

```yaml docker-compose.gpu.yml
services:
  jepa-service:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']  # Specific GPU
              capabilities: [gpu]
        limits:
          memory: 16G
          cpus: '4'

  bionemo-service:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['1']  # Different GPU
              capabilities: [gpu]
        limits:
          memory: 32G
          cpus: '8'
```

## Production deployment

### Multi-stage builds

```dockerfile Dockerfile.production
# Build stage
FROM node:20-alpine AS builder

WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

# Production stage
FROM node:20-alpine

# Security: Run as non-root user
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nodejs -u 1001

WORKDIR /app

# Copy only production dependencies
COPY --from=builder --chown=nodejs:nodejs /app/node_modules ./node_modules
COPY --from=builder --chown=nodejs:nodejs /app/dist ./dist
COPY --from=builder --chown=nodejs:nodejs /app/package*.json ./

USER nodejs

EXPOSE 8080

CMD ["node", "dist/index.js"]
```

### Security hardening

```yaml docker-compose.production.yml
services:
  api-gateway:
    build:
      context: ./services/api-gateway
      dockerfile: Dockerfile.production
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE
    read_only: true
    tmpfs:
      - /tmp
    environment:
      - NODE_ENV=production
    secrets:
      - db_password
      - api_keys

secrets:
  db_password:
    external: true
  api_keys:
    external: true
```

### Resource limits

```yaml docker-compose.limits.yml
services:
  api-gateway:
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
```

## Networking

### Service discovery

```yaml docker-compose.network.yml
services:
  api-gateway:
    networks:
      - frontend
      - backend

  jepa-service:
    networks:
      - backend

  postgres:
    networks:
      - backend

networks:
  frontend:
    driver: bridge
  backend:
    driver: bridge
    internal: true  # No external access
```

### Load balancing

```yaml docker-compose.scale.yml
services:
  api-gateway:
    deploy:
      replicas: 3
      update_config:
        parallelism: 1
        delay: 10s
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - api-gateway
```

## Monitoring and logging

### Logging configuration

```yaml docker-compose.logging.yml
services:
  api-gateway:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service,environment"
        env: "NODE_ENV"

  # Centralized logging with Loki
  loki:
    image: grafana/loki:latest
    ports:
      - "3100:3100"
    volumes:
      - ./monitoring/loki-config.yml:/etc/loki/local-config.yaml
      - loki-data:/loki

  promtail:
    image: grafana/promtail:latest
    volumes:
      - /var/log:/var/log
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - ./monitoring/promtail-config.yml:/etc/promtail/config.yml
    command: -config.file=/etc/promtail/config.yml
```

## Backup and recovery

### Database backups

```bash scripts/backup.sh
#!/bin/bash

# Backup PostgreSQL
docker-compose exec -T postgres pg_dump -U iluminara iluminara | \
  gzip > backups/postgres_$(date +%Y%m%d_%H%M%S).sql.gz

# Backup volumes
docker run --rm \
  -v iluminara_postgres-data:/data \
  -v $(pwd)/backups:/backup \
  alpine tar czf /backup/postgres-volume_$(date +%Y%m%d_%H%M%S).tar.gz /data
```

### Restore procedure

```bash scripts/restore.sh
#!/bin/bash

# Stop services
docker-compose down

# Restore database
gunzip < backups/postgres_20250101_120000.sql.gz | \
  docker-compose exec -T postgres psql -U iluminara iluminara

# Restore volumes
docker run --rm \
  -v iluminara_postgres-data:/data \
  -v $(pwd)/backups:/backup \
  alpine tar xzf /backup/postgres-volume_20250101_120000.tar.gz -C /

# Start services
docker-compose up -d
```

## Troubleshooting

### Common issues

**Container won't start**
```bash
# Check logs
docker-compose logs service-name

# Inspect container
docker inspect container-id

# Check resource usage
docker stats
```

**GPU not detected**
```bash
# Verify NVIDIA runtime
docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi

# Check Docker daemon config
cat /etc/docker/daemon.json
```

**Network connectivity issues**
```bash
# Test inter-service communication
docker-compose exec api-gateway ping jepa-service

# Inspect network
docker network inspect iluminara_iluminara-network
```

## Next steps

<CardGroup cols={2}>
  <Card title="Kubernetes deployment" icon="dharmachakra" href="/deployment/kubernetes">
    Scale with Kubernetes
  </Card>
  <Card title="Serverless deployment" icon="bolt" href="/deployment/serverless">
    Deploy serverless functions
  </Card>
  <Card title="Monitoring setup" icon="chart-line" href="/deployment/monitoring">
    Configure observability
  </Card>
  <Card title="CI/CD pipeline" icon="code-branch" href="/deployment/cicd">
    Automate deployments
  </Card>
</CardGroup>
