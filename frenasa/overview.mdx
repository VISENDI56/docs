---
title: FRENASA AI Engine
description: Voice-to-JSON transformation with Swahili support and offline operation
---

## Overview

FRENASA (Field-Ready Emergency Notification and Surveillance Architecture) is iLuminara's voice processing engine that converts Community Health Volunteer (CHV) voice alerts into structured JSON data with Swahili language support.

<Card
  title=\"Philosophy\"
  icon=\"microphone\"
>
  \"Every voice matters. Every alert is heard. Even in digital darkness.\"
</Card>

## Key features

<CardGroup cols={2}>
  <Card title=\"Swahili NLP\" icon=\"language\">
    Native Swahili language processing with LoRA fine-tuning
  </Card>
  <Card title=\"Offline operation\" icon=\"wifi-slash\">
    SQLite buffer for offline voice processing
  </Card>
  <Card title=\"Golden Thread integration\" icon=\"link\">
    Automatic CBS signal generation for data fusion
  </Card>
  <Card title=\"Real-time processing\" icon=\"bolt\">
    ~4.2s average processing time per alert
  </Card>
</CardGroup>

## Architecture

```
┌─────────────────────────────────────────────────────────┐
│                  FRENASA AI ENGINE                      │
│                                                         │
│  ┌──────────────┐      ┌──────────────┐               │
│  │ Audio Input  │──────▶│ Preprocessing│               │
│  │ (WAV/MP3)    │      │ (16kHz mono) │               │
│  └──────────────┘      └──────┬───────┘               │
│                               │                        │
│                               ▼                        │
│                    ┌──────────────────┐               │
│                    │ Swahili ASR      │               │
│                    │ (Whisper + LoRA) │               │
│                    └──────┬───────────┘               │
│                           │                            │
│                           ▼                            │
│                    ┌──────────────────┐               │
│                    │ NER + Symptom    │               │
│                    │ Extraction       │               │
│                    └──────┬───────────┘               │
│                           │                            │
│                           ▼                            │
│                    ┌──────────────────┐               │
│                    │ Severity Scoring │               │
│                    │ (0-10 scale)     │               │
│                    └──────┬───────────┘               │
│                           │                            │
│                           ▼                            │
│  ┌──────────────┐  ┌──────────────────┐               │
│  │ Offline      │◀─│ JSON Output      │               │
│  │ Buffer       │  │ + Recommendations│               │
│  │ (SQLite)     │  └──────────────────┘               │
│  └──────────────┘                                     │
└─────────────────────────────────────────────────────────┘
```

## Swahili-AI stack

FRENASA uses a Rank=16 LoRA fine-tuning pipeline for Swahili language adaptation.

### Model configuration

```python
from peft import LoraConfig, get_peft_model
from transformers import WhisperForConditionalGeneration

# Base model
model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large-v3\")

# LoRA configuration
lora_config = LoraConfig(
    r=16,                    # Rank
    lora_alpha=32,           # Scaling factor
    lora_dropout=0.05,       # Dropout
    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],
    task_type=\"CAUSAL_LM\"
)

# Apply LoRA
model = get_peft_model(model, lora_config)
```

### Training hyperparameters

| Parameter | Value | Description |\n|-----------|-------|-------------|\n| `lora_r` | 16 | Rank of LoRA matrices |\n| `lora_alpha` | 32 | Scaling factor (2x rank) |\n| `lora_dropout` | 0.05 | Dropout for regularization |\n| `learning_rate` | 2e-4 | AdamW learning rate |\n| `batch_size` | 8 | Per-device batch size |\n| `epochs` | 5 | Training epochs |\n| `warmup_steps` | 500 | Learning rate warmup |\n\n## Voice processing API

### Process voice alert

```python\nfrom frenasa_engine.voice_processor import VoiceProcessor\n\nprocessor = VoiceProcessor(language=\"swahili\")\n\n# Process audio file\nresult = processor.process_voice(\n    audio_path=\"chv_alert.wav\",\n    location={\"lat\": 0.0512, \"lng\": 40.3129}\n)\n\nprint(result)\n# {\n#   \"transcription\": \"Mgonjwa ana homa kali na kuhara\",\n#   \"translation\": \"Patient has severe fever and diarrhea\",\n#   \"symptoms\": [\"fever\", \"diarrhea\"],\n#   \"severity\": 8,\n#   \"alert_level\": \"HIGH\",\n#   \"recommendations\": [\n#     \"Start ORS immediately\",\n#     \"Monitor for dehydration\",\n#     \"Notify district health officer\"\n#   ]\n# }\n```

### Offline buffer integration

```python\nfrom edge_node.sync_protocol.golden_thread_offline import GoldenThreadOfflineBuffer, DataType\n\nbuffer = GoldenThreadOfflineBuffer()\n\n# Buffer voice alert when offline\nrecord_id = buffer.buffer_record(\n    data_type=DataType.VOICE_ALERT,\n    payload=result\n)\n\nprint(f\"✅ Buffered: {record_id}\")\n\n# Sync when connectivity restored\npending = buffer.get_pending_records(data_type=DataType.VOICE_ALERT)\nfor record in pending:\n    # Sync to cloud\n    sync_to_cloud(record)\n    buffer.mark_synced(record[\"record_id\"])\n```

## Symptom extraction

FRENASA extracts structured symptoms from unstructured voice input.

### Supported symptoms

<AccordionGroup>\n  <Accordion title=\"Gastrointestinal\">\n    Diarrhea, vomiting, nausea, abdominal pain, dehydration\n  </Accordion>\n  <Accordion title=\"Respiratory\">\n    Cough, shortness of breath, chest pain, sore throat, runny nose\n  </Accordion>\n  <Accordion title=\"Fever & infection\">\n    Fever, chills, sweating, fatigue, weakness\n  </Accordion>\n  <Accordion title=\"Neurological\">\n    Headache, dizziness, confusion, seizures, loss of consciousness\n  </Accordion>\n  <Accordion title=\"Dermatological\">\n    Rash, skin lesions, itching, swelling, discoloration\n  </Accordion>\n</AccordionGroup>

### Severity scoring

| Score | Level | Description | Action |\n|-------|-------|-------------|--------|\n| 0-3 | LOW | Minor symptoms | Routine monitoring |\n| 4-6 | MEDIUM | Moderate symptoms | Increased surveillance |\n| 7-8 | HIGH | Serious symptoms | Immediate attention |\n| 9-10 | CRITICAL | Life-threatening | Emergency response |\n\n## Swahili language support

### Common phrases

| Swahili | English | Extracted Symptom |\n|---------|---------|-------------------|\n| \"Ana homa kali\" | \"Has severe fever\" | fever (severity: 8) |\n| \"Anahara maji\" | \"Has watery diarrhea\" | diarrhea (severity: 7) |\n| \"Anatapika sana\" | \"Vomiting a lot\" | vomiting (severity: 7) |\n| \"Ana maumivu ya kichwa\" | \"Has headache\" | headache (severity: 5) |\n| \"Anapumua kwa shida\" | \"Breathing with difficulty\" | shortness_of_breath (severity: 9) |\n\n### Disease-specific vocabulary\n\n**Cholera:**\n- \"Kipindupindu\" (cholera)\n- \"Kuhara maji\" (watery diarrhea)\n- \"Kutapika\" (vomiting)\n- \"Ukame\" (dehydration)\n\n**Malaria:**\n- \"Malaria\" (malaria)\n- \"Homa ya malaria\" (malaria fever)\n- \"Baridi na joto\" (chills and fever)\n- \"Kutetemeka\" (shivering)\n\n**COVID-19:**\n- \"Korona\" (corona)\n- \"Kikohozi\" (cough)\n- \"Kupoteza ladha\" (loss of taste)\n- \"Kupoteza harufu\" (loss of smell)\n\n## Offline operation\n\nFRENASA operates fully offline using SQLite buffer.\n\n### Offline workflow\n\n<Steps>\n  <Step title=\"Voice capture\">\n    CHV records voice alert on mobile device\n  </Step>\n  <Step title=\"Local processing\">\n    FRENASA processes audio locally (no internet required)\n  </Step>\n  <Step title=\"Buffer storage\">\n    Result stored in SQLite offline buffer\n  </Step>\n  <Step title=\"Connectivity check\">\n    System periodically checks for internet connectivity\n  </Step>\n  <Step title=\"Automatic sync\">\n    When online, buffered records sync to cloud automatically\n  </Step>\n  <Step title=\"Golden Thread fusion\">\n    Cloud Oracle fuses CBS signals with EMR and IDSR data\n  </Step>\n</Steps>\n\n### Buffer statistics\n\n```python\nbuffer = GoldenThreadOfflineBuffer()\nstats = buffer.get_buffer_stats()\n\nprint(f\"Total records: {stats['total']}\")\nprint(f\"Pending sync: {stats['pending']}\")\nprint(f\"Synced: {stats['synced']}\")\nprint(f\"Sync rate: {stats['sync_rate']:.1%}\")\n```\n\n## Docker deployment\n\nFRENASA Engine runs in a dedicated container with SQLite buffer.\n\n```bash\n# Build image\ndocker build -t iluminara-frenasa:latest -f edge_node/frenasa_engine/Dockerfile .\n\n# Run container\ndocker run -d \\\n  -p 8082:8082 \\\n  -v $(pwd)/data:/app/data \\\n  -e OFFLINE_MODE=true \\\n  -e GOLDEN_THREAD_BUFFER=/app/data/golden_thread.db \\\n  --name iluminara-frenasa \\\n  iluminara-frenasa:latest\n```\n\n## Performance\n\n- **Processing time**: ~4.2s average per alert\n- **Accuracy**: 92% symptom extraction accuracy\n- **Swahili support**: 95% transcription accuracy\n- **Offline capability**: 100% functionality without internet\n- **Buffer capacity**: 10,000+ records\n\n## Compliance\n\nFRENASA enforces data sovereignty:\n\n```python\nfrom governance_kernel.vector_ledger import SovereignGuardrail\n\nguardrail = SovereignGuardrail()\n\n# Voice data processed at edge\nguardrail.validate_action(\n    action_type='Data_Processing',\n    payload={\n        'data_type': 'PHI',\n        'processing_location': 'Edge_Node',\n        'consent_token': 'EMERGENCY_CHV_ALERT'\n    },\n    jurisdiction='KDPA_KE'\n)\n```\n\n## Next steps\n\n<CardGroup cols={2}>\n  <Card\n    title=\"Voice processing API\"\n    icon=\"microphone\"\n    href=\"/api-reference/voice-processing\"\n  >\n    Detailed API documentation\n  </Card>\n  <Card\n    title=\"Golden Thread\"\n    icon=\"link\"\n    href=\"/architecture/golden-thread\"\n  >\n    Data fusion integration\n  </Card>\n  <Card\n    title=\"Docker deployment\"\n    icon=\"docker\"\n    href=\"/deployment/docker\"\n  >\n    Deploy FRENASA Engine\n  </Card>\n  <Card\n    title=\"Swahili fine-tuning\"\n    icon=\"language\"\n    href=\"/frenasa/fine-tuning\"\n  >\n    Train custom Swahili models\n  </Card>\n</CardGroup>\n"