"""
HSML Offline-First Sync Agent
Implements resilient "disconnected" mode for frontline humanitarian workers.

Features:
- Local-first SQLite/DuckDB buffer for HSML events
- Vector Clock conflict resolution
- 0% data loss during offline operations
- Automatic reconciliation with Golden Thread

Compliance:
- GDPR Art. 32 (Security of Processing)
- HIPAA Â§164.312(b) (Audit Controls)
- ISO 27001 A.12.4 (Logging and Monitoring)
"""

import sqlite3
import json
import hashlib
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from enum import Enum
from dataclasses import dataclass, asdict
import logging

logger = logging.getLogger(__name__)


class SyncStatus(Enum):
    """Synchronization status"""
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    SYNCED = "synced"
    CONFLICT = "conflict"
    FAILED = "failed"


class EventType(Enum):
    """HSML event types"""
    CBS_REPORT = "cbs_report"
    EMR_RECORD = "emr_record"
    IDSR_SUBMISSION = "idsr_submission"
    VOICE_ALERT = "voice_alert"
    SENSOR_READING = "sensor_reading"
    OUTBREAK_ALERT = "outbreak_alert"


@dataclass
class VectorClock:
    """
    Vector Clock for distributed conflict resolution.
    
    Each node maintains a vector of logical timestamps.
    Conflicts are resolved by comparing vector clocks.
    """
    node_id: str
    clock: Dict[str, int]
    
    def increment(self):
        """Increment this node's clock"""
        self.clock[self.node_id] = self.clock.get(self.node_id, 0) + 1
    
    def update(self, other: 'VectorClock'):
        """Update clock with another vector clock"""
        for node_id, timestamp in other.clock.items():
            self.clock[node_id] = max(self.clock.get(node_id, 0), timestamp)
        self.increment()
    
    def happens_before(self, other: 'VectorClock') -> bool:
        """Check if this event happens before another"""
        return (
            all(self.clock.get(k, 0) <= other.clock.get(k, 0) for k in self.clock)
            and any(self.clock.get(k, 0) < other.clock.get(k, 0) for k in self.clock)
        )
    
    def concurrent_with(self, other: 'VectorClock') -> bool:
        """Check if events are concurrent (conflict)"""
        return not self.happens_before(other) and not other.happens_before(self)
    
    def to_dict(self) -> Dict:
        return {"node_id": self.node_id, "clock": self.clock}
    
    @classmethod
    def from_dict(cls, data: Dict) -> 'VectorClock':
        return cls(node_id=data["node_id"], clock=data["clock"])


@dataclass
class HSMLEvent:
    """Health Sovereign Markup Language Event"""
    event_id: str
    event_type: EventType
    node_id: str
    timestamp: str
    vector_clock: VectorClock
    payload: Dict
    hash: str
    sync_status: SyncStatus
    retry_count: int = 0
    last_sync_attempt: Optional[str] = None
    
    def to_dict(self) -> Dict:
        return {
            "event_id": self.event_id,
            "event_type": self.event_type.value,
            "node_id": self.node_id,
            "timestamp": self.timestamp,
            "vector_clock": self.vector_clock.to_dict(),
            "payload": self.payload,
            "hash": self.hash,
            "sync_status": self.sync_status.value,
            "retry_count": self.retry_count,
            "last_sync_attempt": self.last_sync_attempt
        }
    
    @classmethod
    def from_dict(cls, data: Dict) -> 'HSMLEvent':
        return cls(
            event_id=data["event_id"],
            event_type=EventType(data["event_type"]),
            node_id=data["node_id"],
            timestamp=data["timestamp"],
            vector_clock=VectorClock.from_dict(data["vector_clock"]),
            payload=data["payload"],
            hash=data["hash"],
            sync_status=SyncStatus(data["sync_status"]),
            retry_count=data.get("retry_count", 0),
            last_sync_attempt=data.get("last_sync_attempt")
        )


class HSMLSyncAgent:
    """
    Offline-First Sync Agent with Vector Clock reconciliation.
    
    Ensures 0% data loss during offline humanitarian operations.
    """
    
    def __init__(
        self,
        node_id: str,
        db_path: str = "./hsml_buffer.db",
        max_retry_attempts: int = 5,
        retry_backoff_seconds: int = 60
    ):
        self.node_id = node_id
        self.db_path = db_path
        self.max_retry_attempts = max_retry_attempts
        self.retry_backoff_seconds = retry_backoff_seconds
        
        # Initialize vector clock
        self.vector_clock = VectorClock(node_id=node_id, clock={node_id: 0})
        
        # Initialize database
        self._init_database()
        
        logger.info(f"ðŸ”„ HSML Sync Agent initialized - Node: {node_id}")
    
    def _init_database(self):
        """Initialize SQLite database for local buffer"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Create events table
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS hsml_events (
                event_id TEXT PRIMARY KEY,
                event_type TEXT NOT NULL,
                node_id TEXT NOT NULL,
                timestamp TEXT NOT NULL,
                vector_clock TEXT NOT NULL,
                payload TEXT NOT NULL,
                hash TEXT NOT NULL,
                sync_status TEXT NOT NULL,
                retry_count INTEGER DEFAULT 0,
                last_sync_attempt TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # Create index for sync status
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_sync_status 
            ON hsml_events(sync_status)
        """)
        
        # Create index for timestamp
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_timestamp 
            ON hsml_events(timestamp)
        """)
        
        conn.commit()
        conn.close()
        
        logger.info(f"âœ… Database initialized: {self.db_path}")
    
    def create_event(
        self,
        event_type: EventType,
        payload: Dict
    ) -> HSMLEvent:
        """
        Create a new HSML event with vector clock.
        
        Args:
            event_type: Type of event
            payload: Event data
        
        Returns:
            HSMLEvent with vector clock
        """
        # Increment vector clock
        self.vector_clock.increment()
        
        # Generate event ID
        timestamp = datetime.utcnow().isoformat()
        event_id = hashlib.sha256(
            f"{self.node_id}:{timestamp}:{json.dumps(payload)}".encode()
        ).hexdigest()[:16]
        
        # Calculate hash
        event_hash = hashlib.sha256(
            json.dumps({
                "event_id": event_id,
                "event_type": event_type.value,
                "node_id": self.node_id,
                "timestamp": timestamp,
                "payload": payload
            }, sort_keys=True).encode()
        ).hexdigest()
        
        # Create event
        event = HSMLEvent(
            event_id=event_id,
            event_type=event_type,
            node_id=self.node_id,
            timestamp=timestamp,
            vector_clock=VectorClock(
                node_id=self.node_id,
                clock=self.vector_clock.clock.copy()
            ),
            payload=payload,
            hash=event_hash,
            sync_status=SyncStatus.PENDING
        )
        
        # Store in local buffer
        self._store_event(event)
        
        logger.info(f"ðŸ“ Event created: {event_id} (Type: {event_type.value})")
        
        return event
    
    def _store_event(self, event: HSMLEvent):
        """Store event in local buffer"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT OR REPLACE INTO hsml_events 
            (event_id, event_type, node_id, timestamp, vector_clock, 
             payload, hash, sync_status, retry_count, last_sync_attempt)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            event.event_id,
            event.event_type.value,
            event.node_id,
            event.timestamp,
            json.dumps(event.vector_clock.to_dict()),
            json.dumps(event.payload),
            event.hash,
            event.sync_status.value,
            event.retry_count,
            event.last_sync_attempt
        ))
        
        conn.commit()
        conn.close()
    
    def get_pending_events(self, limit: int = 100) -> List[HSMLEvent]:
        """Get events pending synchronization"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT event_id, event_type, node_id, timestamp, vector_clock,
                   payload, hash, sync_status, retry_count, last_sync_attempt
            FROM hsml_events
            WHERE sync_status = ?
            ORDER BY timestamp ASC
            LIMIT ?
        """, (SyncStatus.PENDING.value, limit))
        
        events = []
        for row in cursor.fetchall():
            event = HSMLEvent(
                event_id=row[0],
                event_type=EventType(row[1]),
                node_id=row[2],
                timestamp=row[3],
                vector_clock=VectorClock.from_dict(json.loads(row[4])),
                payload=json.loads(row[5]),
                hash=row[6],
                sync_status=SyncStatus(row[7]),
                retry_count=row[8],
                last_sync_attempt=row[9]
            )
            events.append(event)
        
        conn.close()
        
        return events
    
    def reconcile_conflict(
        self,
        local_event: HSMLEvent,
        remote_event: HSMLEvent
    ) -> HSMLEvent:
        """
        Reconcile conflict using vector clock.
        
        Resolution strategy:
        1. If one event happens-before the other, keep the later one
        2. If concurrent, merge payloads with conflict markers
        3. Update vector clock to reflect resolution
        
        Args:
            local_event: Event from local buffer
            remote_event: Event from Golden Thread
        
        Returns:
            Resolved event
        """
        logger.warning(f"âš ï¸ Conflict detected: {local_event.event_id} vs {remote_event.event_id}")
        
        # Check happens-before relationship
        if local_event.vector_clock.happens_before(remote_event.vector_clock):
            logger.info(f"âœ… Remote event is newer - accepting remote")
            return remote_event
        
        elif remote_event.vector_clock.happens_before(local_event.vector_clock):
            logger.info(f"âœ… Local event is newer - keeping local")
            return local_event
        
        else:
            # Concurrent events - merge with conflict markers
            logger.warning(f"ðŸ”€ Concurrent events - merging with conflict markers")
            
            merged_payload = {
                "_conflict": True,
                "_resolution_strategy": "merge",
                "_local": local_event.payload,
                "_remote": remote_event.payload,
                "_merged_at": datetime.utcnow().isoformat()
            }
            
            # Create merged event with updated vector clock
            merged_event = HSMLEvent(
                event_id=f"{local_event.event_id}_merged",
                event_type=local_event.event_type,
                node_id=self.node_id,
                timestamp=datetime.utcnow().isoformat(),
                vector_clock=VectorClock(
                    node_id=self.node_id,
                    clock=local_event.vector_clock.clock.copy()
                ),
                payload=merged_payload,
                hash=hashlib.sha256(json.dumps(merged_payload).encode()).hexdigest(),
                sync_status=SyncStatus.CONFLICT
            )
            
            # Update vector clock
            merged_event.vector_clock.update(remote_event.vector_clock)
            
            return merged_event
    
    def sync_to_golden_thread(
        self,
        golden_thread_client,
        batch_size: int = 50
    ) -> Dict:
        """
        Synchronize pending events to Golden Thread.
        
        Args:
            golden_thread_client: Client for Golden Thread API
            batch_size: Number of events to sync per batch
        
        Returns:
            Sync statistics
        """
        pending_events = self.get_pending_events(limit=batch_size)
        
        stats = {
            "total": len(pending_events),
            "synced": 0,
            "conflicts": 0,
            "failed": 0
        }
        
        for event in pending_events:
            try:
                # Check if event exists in Golden Thread
                remote_event = golden_thread_client.get_event(event.event_id)
                
                if remote_event:
                    # Conflict - reconcile
                    resolved_event = self.reconcile_conflict(event, remote_event)
                    
                    if resolved_event.sync_status == SyncStatus.CONFLICT:
                        stats["conflicts"] += 1
                        # Store conflict for manual review
                        self._store_event(resolved_event)
                    else:
                        # Push resolved event
                        golden_thread_client.push_event(resolved_event)
                        event.sync_status = SyncStatus.SYNCED
                        self._store_event(event)
                        stats["synced"] += 1
                else:
                    # No conflict - push event
                    golden_thread_client.push_event(event)
                    event.sync_status = SyncStatus.SYNCED
                    self._store_event(event)
                    stats["synced"] += 1
                
            except Exception as e:
                logger.error(f"âŒ Sync failed for {event.event_id}: {e}")
                event.retry_count += 1
                event.last_sync_attempt = datetime.utcnow().isoformat()
                
                if event.retry_count >= self.max_retry_attempts:
                    event.sync_status = SyncStatus.FAILED
                    stats["failed"] += 1
                
                self._store_event(event)
        
        logger.info(f"ðŸ”„ Sync complete - Synced: {stats['synced']}, Conflicts: {stats['conflicts']}, Failed: {stats['failed']}")
        
        return stats
    
    def get_buffer_stats(self) -> Dict:
        """Get statistics about local buffer"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT sync_status, COUNT(*) 
            FROM hsml_events 
            GROUP BY sync_status
        """)
        
        stats = {row[0]: row[1] for row in cursor.fetchall()}
        
        cursor.execute("SELECT COUNT(*) FROM hsml_events")
        stats["total"] = cursor.fetchone()[0]
        
        conn.close()
        
        return stats


# Example usage
if __name__ == "__main__":
    # Initialize sync agent
    agent = HSMLSyncAgent(node_id="JOR-47")
    
    # Create offline events
    event1 = agent.create_event(
        event_type=EventType.CBS_REPORT,
        payload={
            "location": "Dadaab",
            "symptom": "diarrhea",
            "severity": 8,
            "reporter": "CHV_AMINA_HASSAN"
        }
    )
    
    event2 = agent.create_event(
        event_type=EventType.VOICE_ALERT,
        payload={
            "location": "Dadaab",
            "transcription": "Patient reporting severe dehydration",
            "language": "swahili"
        }
    )
    
    # Check buffer stats
    stats = agent.get_buffer_stats()
    print(f"ðŸ“Š Buffer Stats: {json.dumps(stats, indent=2)}")
    
    # Simulate sync (when connectivity returns)
    # stats = agent.sync_to_golden_thread(golden_thread_client)
